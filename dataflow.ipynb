{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ottos\\akariinc\\YOLaT-VectorGraphicsRecognition\n"
     ]
    }
   ],
   "source": [
    "%cd cad_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __init__\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "import time\n",
    "from itertools import repeat, product\n",
    "\n",
    "#from torch_geometric.data import DataLoader, DataListLoader\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import functional as F\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn.data_parallel import DataParallel\n",
    "from cad_recognition.config import OptInit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import argparse\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import logging\n",
    "import logging.config\n",
    "import pathlib\n",
    "import glob\n",
    "import time\n",
    "import uuid\n",
    "import sys\n",
    "\n",
    "class ColabOptInit(OptInit):\n",
    "    def __init__(self, command_args):\n",
    "        parse = \"\"\"\n",
    "                parser.add_argument('--phase', default='test', type=str, help='train or test(default)')\n",
    "                parser.add_argument('--use_cpu', action='store_true', help='use cpu?')\n",
    "                parser.add_argument('--exp_name', type=str, default='sem_seg_sparse', help='prefix of saved file')\n",
    "                parser.add_argument('--root_dir', type=str, default='log', help='the dir of experiment results')\n",
    "                parser.add_argument('--data_dir', type=str, default='/data/deepgcn/S3DIS')\n",
    "                parser.add_argument('--batch_size', default=16, type=int, help='mini-batch size (default:16)')\n",
    "                parser.add_argument('--in_channels', default=6, type=int, help='the channel size of input point cloud ')\n",
    "                parser.add_argument('--total_epochs', default=200, type=int, help='number of total epochs to run')\n",
    "                parser.add_argument('--save_freq', default=5, type=int, help='save model per num of epochs')\n",
    "                parser.add_argument('--iter', default=0, type=int, help='number of iteration to start')\n",
    "                parser.add_argument('--lr_adjust_freq', default=20, type=int, help='decay lr after certain number of epoch')\n",
    "                parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate')\n",
    "                parser.add_argument('--lr_decay_rate', default=0.5, type=float, help='learning rate decay')\n",
    "                parser.add_argument('--print_freq', default=5, type=int, help='print frequency of training (default: 100)')\n",
    "                parser.add_argument('--postname', type=str, default='', help='postname of saved file')\n",
    "                parser.add_argument('--multi_gpus', action='store_true', help='use multi-gpus')\n",
    "                parser.add_argument('--seed', type=int, default=0, help='random seed')\n",
    "                parser.add_argument('--pos_edge_th', type=float, default=5e-3, help='threshold to build edge')\n",
    "                parser.add_argument('--lambda_class', type=float, default=1, help='threshold to build edge')\n",
    "                parser.add_argument('--lambda_offset', type=float, default=1, help='threshold to build edge')\n",
    "                parser.add_argument('--lambda_size', type=float, default=10, help='threshold to build edge')\n",
    "                parser.add_argument('--classifier', type=str, default='softmax', help='threshold to build edge')\n",
    "                parser.add_argument('--weight_decay', type=float, default=0, help='threshold to build edge')\n",
    "                parser.add_argument('--data_aug', type=bool, default=False, help='threshold to build edge')\n",
    "                parser.add_argument('--se_node_only', type=int, default=0, help='threshold to build edge')\n",
    "                parser.add_argument('--do_mixup', type=float, default=0, help='threshold to build edge')\n",
    "                parser.add_argument('--bbox_sampling_step', type=int, default=10, help='threshold to build edge')\n",
    "                parser.add_argument('--ohem', type=float, default=-1, help='threshold to build edge')\n",
    "                parser.add_argument('--drop_edge', type=float, default=0, help='threshold to build edge')\n",
    "                parser.add_argument('--no_clutter', action='store_true', help='no clutter? set --no_clutter if ture.')\n",
    "                parser.add_argument('--map_step', type=int, default=10, help='threshold to build edge')\n",
    "                parser.add_argument('--pretrained_model', type=str, help='path to pretrained model(default: none)', default='')\n",
    "                parser.add_argument('--k', default=16, type=int, help='neighbor num (default:16)')\n",
    "                parser.add_argument('--block', default='res', type=str, help='graph backbone block type {plain, res, dense}')\n",
    "                parser.add_argument('--conv', default='attr_edge', type=str, help='graph conv layer {edge, mr}')\n",
    "                parser.add_argument('--act', default='relu', type=str, help='activation layer {relu, prelu, leakyrelu}')\n",
    "                parser.add_argument('--norm', default='batch', type=str, help='{batch, instance} normalization')\n",
    "                parser.add_argument('--bias', default=True,  type=bool, help='bias of conv layer True or False')\n",
    "                parser.add_argument('--n_filters', default=64, type=int, help='number of channels of deep features')\n",
    "                parser.add_argument('--n_blocks', default=14, type=int, help='number of basic blocks')\n",
    "                parser.add_argument('--n_blocks_out', default=7, type=int, help='number of basic blocks')\n",
    "                parser.add_argument('--dropout', default=0.3, type=float, help='ratio of dropout')\n",
    "                parser.add_argument('--arch', default='centernet', type=str, help='ratio of dropout')\n",
    "                parser.add_argument('--class_specific', default=False, type=bool, help='ratio of dropout')\n",
    "                parser.add_argument('--graph', default='bezier', type=str, help='ratio of dropout')\n",
    "                parser.add_argument('--n_edges', default=3, type=int, help='ratio of dropout')\n",
    "                parser.add_argument('--epsilon', default=0.2, type=float, help='stochastic epsilon for gcn')\n",
    "                parser.add_argument('--stochastic', default=True,  type=bool, help='stochastic for gcn, True or False')\n",
    "                \"\"\"\n",
    "\n",
    "        pargs = {}\n",
    "        args = argparse.Namespace()\n",
    "\n",
    "        for line in parse.split('\\n'):\n",
    "            if 'default=' in line:\n",
    "                name = re.search(r'--(.*?)\\'', line).group(1)\n",
    "                pargs[name] = eval(re.search(r'default=(.*?)(\\)|,)', line).group(1))\n",
    "            elif 'action=' in line:\n",
    "                name = re.search(r'--(.*?)\\'', line).group(1)\n",
    "                pargs[name] = False\n",
    "        for key in pargs:\n",
    "            args.__setattr__(key, pargs[key])\n",
    "\n",
    "        for line in command_args.split('\\n'):\n",
    "            name, val = line.strip('--').split()\n",
    "            if val[0].isnumeric():\n",
    "                val = eval(val)\n",
    "            args.__setattr__(name, val)\n",
    "\n",
    "        args.device = torch.device('cuda' if not args.use_cpu and torch.cuda.is_available() else 'cpu')\n",
    "        self.args = args\n",
    "        self._set_seed(self.args.seed)\n",
    "\n",
    "        # ===> generate log dir\n",
    "        if self.args.phase == 'train':\n",
    "            self._generate_exp_directory()\n",
    "            # logger\n",
    "            self.args.writer = SummaryWriter(log_dir=self.args.exp_dir)\n",
    "            # loss\n",
    "            self.args.epoch = -1\n",
    "            self.args.step = -1\n",
    "\n",
    "        else:\n",
    "            self.args.exp_dir = os.path.dirname(args.pretrained_model)\n",
    "            self.args.res_dir = os.path.join(self.args.exp_dir, 'result', args.block)\n",
    "            pathlib.Path(self.args.res_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self._configure_logger()\n",
    "        self._print_args()\n",
    "\n",
    "    def _configure_logger(self):\n",
    "        \"\"\"\n",
    "        Configure logger on given level. Logging will occur on standard\n",
    "        output and in a log file saved in model_dir.\n",
    "        \"\"\"\n",
    "        self.args.loglevel = \"info\"\n",
    "        numeric_level = getattr(logging, self.args.loglevel.upper(), None)\n",
    "        if not isinstance(numeric_level, int):\n",
    "            raise ValueError('Invalid log level: {}'.format(self.args.loglevelloglevel))\n",
    "\n",
    "            # configure logger to display and save log data\n",
    "        # log_format = logging.Formatter('%(asctime)s [%(levelname)-5.5s] [%(filename)s:%(lineno)04d] %(message)s')\n",
    "        log_format = logging.Formatter('%(asctime)s %(message)s')\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(numeric_level)\n",
    "\n",
    "        file_handler = logging.FileHandler('../test.log')\n",
    "        file_handler.setFormatter(log_format)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "        file_handler = logging.StreamHandler(sys.stdout)\n",
    "        file_handler.setFormatter(log_format)\n",
    "        logger.addHandler(file_handler)\n",
    "        logging.root = logger\n",
    "        logging.info(\"saving log, checkpoint and back up code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_args = \"\"\"--total_epochs 20 \n",
    "--batch_size 4 \n",
    "--data_dir data/FloorPlansGraph5_iter \n",
    "--phase train \n",
    "--lr 2.5e-4 \n",
    "--lr_adjust_freq 9999999999999999999999999999999999999 \n",
    "--in_channels 5 \n",
    "--n_blocks 2 \n",
    "--n_blocks_out 2 \n",
    "--arch centernet3cc_rpn_gp_iter2  \n",
    "--graph bezier_cc_bb_iter \n",
    "--data_aug false \n",
    "--weight_decay 1e-5 \n",
    "--postname run182_2 \n",
    "--dropout 0.0 \n",
    "--do_mixup 0 \n",
    "--bbox_sampling_step 10\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-08-05 14:36:58,509 saving log, checkpoint and back up code\n",
      "2022-08-05 14:36:58,510 ==========       args      =============\n",
      "2022-08-05 14:36:58,511 phase:train\n",
      "2022-08-05 14:36:58,511 use_cpu:False\n",
      "2022-08-05 14:36:58,512 exp_name:sem_seg_sparse\n",
      "2022-08-05 14:36:58,513 root_dir:log\n",
      "2022-08-05 14:36:58,513 data_dir:data/FloorPlansGraph5_iter\n",
      "2022-08-05 14:36:58,514 batch_size:4\n",
      "2022-08-05 14:36:58,514 in_channels:5\n",
      "2022-08-05 14:36:58,515 total_epochs:20\n",
      "2022-08-05 14:36:58,515 save_freq:5\n",
      "2022-08-05 14:36:58,516 iter:0\n",
      "2022-08-05 14:36:58,516 lr_adjust_freq:9999999999999999999999999999999999999\n",
      "2022-08-05 14:36:58,517 lr:0.00025\n",
      "2022-08-05 14:36:58,517 lr_decay_rate:0.5\n",
      "2022-08-05 14:36:58,518 print_freq:5\n",
      "2022-08-05 14:36:58,518 postname:run182_2\n",
      "2022-08-05 14:36:58,519 multi_gpus:False\n",
      "2022-08-05 14:36:58,519 seed:0\n",
      "2022-08-05 14:36:58,519 pos_edge_th:0.005\n",
      "2022-08-05 14:36:58,520 lambda_class:1\n",
      "2022-08-05 14:36:58,521 lambda_offset:1\n",
      "2022-08-05 14:36:58,521 lambda_size:10\n",
      "2022-08-05 14:36:58,522 classifier:softmax\n",
      "2022-08-05 14:36:58,522 weight_decay:1e-05\n",
      "2022-08-05 14:36:58,522 data_aug:false\n",
      "2022-08-05 14:36:58,523 se_node_only:0\n",
      "2022-08-05 14:36:58,523 do_mixup:0\n",
      "2022-08-05 14:36:58,524 bbox_sampling_step:10\n",
      "2022-08-05 14:36:58,524 ohem:-1\n",
      "2022-08-05 14:36:58,525 drop_edge:0\n",
      "2022-08-05 14:36:58,525 no_clutter:False\n",
      "2022-08-05 14:36:58,526 map_step:10\n",
      "2022-08-05 14:36:58,526 pretrained_model:\n",
      "2022-08-05 14:36:58,526 k:16\n",
      "2022-08-05 14:36:58,527 block:res\n",
      "2022-08-05 14:36:58,528 conv:attr_edge\n",
      "2022-08-05 14:36:58,528 act:relu\n",
      "2022-08-05 14:36:58,529 norm:batch\n",
      "2022-08-05 14:36:58,529 bias:True\n",
      "2022-08-05 14:36:58,529 n_filters:64\n",
      "2022-08-05 14:36:58,530 n_blocks:2\n",
      "2022-08-05 14:36:58,530 n_blocks_out:2\n",
      "2022-08-05 14:36:58,531 dropout:0.0\n",
      "2022-08-05 14:36:58,531 arch:centernet3cc_rpn_gp_iter2\n",
      "2022-08-05 14:36:58,532 class_specific:False\n",
      "2022-08-05 14:36:58,532 graph:bezier_cc_bb_iter\n",
      "2022-08-05 14:36:58,533 n_edges:3\n",
      "2022-08-05 14:36:58,533 epsilon:0.2\n",
      "2022-08-05 14:36:58,533 stochastic:True\n",
      "2022-08-05 14:36:58,534 device:cuda\n",
      "2022-08-05 14:36:58,535 jobname:sem_seg_sparse-res-attr_edge-n2-C64-k16-drop0.0-lr0.00025_B4\n",
      "2022-08-05 14:36:58,535 exp_dir:log\\sem_seg_sparse-res-attr_edge-n2-C64-k16-drop0.0-lr0.00025_B4_20220805-143658_0fafe7c7-6e43-4066-865f-9d53e8988097\n",
      "2022-08-05 14:36:58,536 ckpt_dir:log\\sem_seg_sparse-res-attr_edge-n2-C64-k16-drop0.0-lr0.00025_B4_20220805-143658_0fafe7c7-6e43-4066-865f-9d53e8988097\\checkpoint\n",
      "2022-08-05 14:36:58,536 code_dir:log\\sem_seg_sparse-res-attr_edge-n2-C64-k16-drop0.0-lr0.00025_B4_20220805-143658_0fafe7c7-6e43-4066-865f-9d53e8988097\\code\n",
      "2022-08-05 14:36:58,536 writer:<torch.utils.tensorboard.writer.SummaryWriter object at 0x00000118E7C96730>\n",
      "2022-08-05 14:36:58,537 epoch:-1\n",
      "2022-08-05 14:36:58,538 step:-1\n",
      "2022-08-05 14:36:58,538 loglevel:info\n",
      "2022-08-05 14:36:58,539 ==========     args END    =============\n",
      "2022-08-05 14:36:58,539 \n",
      "\n",
      "2022-08-05 14:36:58,539 ===> Phase is train.\n",
      "2022-08-05 14:36:58,540 ===> Creating dataloader ...\n"
     ]
    }
   ],
   "source": [
    "# 既存のloggerを停止\n",
    "for h in logging.getLogger().handlers:\n",
    "    logging.getLogger().removeHandler(h)\n",
    "    h.close()\n",
    "opt = ColabOptInit(command_args).get_args()\n",
    "logging.info('===> Creating dataloader ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CADDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import cv2\n",
    "import random\n",
    "from xml.dom.minidom import parse, Node\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from Datasets.svg_parser import SVGParser\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from utils.det_util import bbox_iou_ios_cpu, intersect_bb_idx\n",
    "\n",
    "class idxTree:\n",
    "    def __init__(self):\n",
    "        self.children = []\n",
    "        self.value = {}\n",
    "\n",
    "class CADDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, opt, \n",
    "        partition = 'train', \n",
    "        data_aug = False, \n",
    "        do_mixup = True, \n",
    "        drop_edge = 0, \n",
    "        bbox_file_postfix = '_bb.pkl', \n",
    "        bbox_sampling_step = 5):\n",
    "        super(CADDataset, self).__init__() \n",
    "        \n",
    "        svg_list = open(os.path.join(root, partition + '_list.txt')).readlines()\n",
    "        svg_list = [os.path.join(root, line.strip()) for line in svg_list]\n",
    "        #print(svg_list)\n",
    "\n",
    "        self.pos_edge_th = opt.pos_edge_th\n",
    "        self.data_aug = data_aug\n",
    "        self.svg_list = svg_list\n",
    "        self.bbox_sampling_step = bbox_sampling_step\n",
    "        self.bbox_file_postfix = bbox_file_postfix\n",
    "        \n",
    "        stats = pickle.load(open(os.path.join(root, 'stats.pkl'), 'rb'))\n",
    "        self.attr_mean = np.array([stats['angles']['mean'], stats['distances']['mean']])\n",
    "        self.attr_std = np.array([stats['angles']['std'], stats['distances']['std']])\n",
    "\n",
    "        self.normalize_bbox = True\n",
    "        self.do_mixup = do_mixup\n",
    "        \n",
    "        if 'diagram' in os.path.dirname(svg_list[0]):\n",
    "            self.class_dict = {\n",
    "                'diode2':0, \n",
    "                'capacitor2': 1, \n",
    "                'diode3': 2, \n",
    "                'earth': 3, \n",
    "                'battery1': 4, \n",
    "                'battery2': 5, \n",
    "                'core-iron': 6, \n",
    "                'outlet': 7, \n",
    "                'transistor-npn': 8, \n",
    "                'capacitor1': 9, \n",
    "                'resistor': 10, \n",
    "                'relay': 11, \n",
    "                'core-air': 12, \n",
    "                'transistor-mosfetn': 13, \n",
    "                'transistor-mosfetp': 14, \n",
    "                'core-hiron': 15, \n",
    "                'transistor-pnp': 16, \n",
    "                'diode1': 17, \n",
    "                'diodephoto': 18, \n",
    "                'gate-ampli':19, \n",
    "                'unspecified': 20, \n",
    "                'None': 21\n",
    "            }\n",
    "\n",
    "        else:\n",
    "            self.class_dict = {\n",
    "                'armchair':0, \n",
    "                'bed':1, \n",
    "                'door1':2, \n",
    "                'door2':3, \n",
    "                'sink1':4, \n",
    "                'sink2':5, \n",
    "                'sink3':6, \n",
    "                'sink4':7, \n",
    "                'sofa1':8, \n",
    "                'sofa2':9, \n",
    "                'table1':10, \n",
    "                'table2':11, \n",
    "                'table3':12, \n",
    "                'tub':13, \n",
    "                'window1':14, \n",
    "                'window2':15, \n",
    "                'None': 16\n",
    "            }\n",
    "\n",
    "        self.n_classes = len(list(self.class_dict.keys()))\n",
    "        \n",
    "        self.n_objects = 13238\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.svg_list)\n",
    "        \n",
    "    def get_anchor(self):\n",
    "        bboxes = [[] for i in range(len(list(self.class_dict.keys())))]\n",
    "        for filepath in self.svg_list:\n",
    "            p = SVGParser(filepath)\n",
    "            width, height = p.get_image_size()\n",
    "            gt_bbox, gt_labels = self._get_bbox(filepath, width, height)\n",
    "            whs = gt_bbox[:, 2:] -  gt_bbox[:, 0:2]\n",
    "            for wh, l in zip(whs, gt_labels):\n",
    "                print(l)\n",
    "                bboxes[l].append(wh)\n",
    "            \n",
    "        bboxes = np.array(bboxes)\n",
    "        for wh in bboxes:\n",
    "            mean_box = np.median(wh, 0)\n",
    "            print(mean_box, np.mean(wh, 0), np.max(wh, 0), np.min(wh, 0))\n",
    "        print(bboxes.shape)\n",
    "        raise SystemExit\n",
    "\n",
    "    def _get_bbox(self, path, width, height):\n",
    "        dom = parse(path.replace('.svg', '.xml'))\n",
    "        root = dom.documentElement\n",
    "\n",
    "        nodes = []\n",
    "        for tagname in ['a', 'o']:\n",
    "            nodes += root.getElementsByTagName(tagname)\n",
    "        \n",
    "        bbox = []\n",
    "        labels = []\n",
    "        for node in nodes:\n",
    "            for n in node.childNodes:\n",
    "                if n.nodeType != Node.ELEMENT_NODE:\n",
    "                    continue\n",
    "                x0 = float(n.getAttribute('x0')) / width\n",
    "                y0 = float(n.getAttribute('y0')) / height\n",
    "                x1 = float(n.getAttribute('x1')) / width \n",
    "                y1 = float(n.getAttribute('y1')) / height\n",
    "                label = n.getAttribute('label')\n",
    "                bbox.append((x0, y0, x1, y1))\n",
    "                labels.append(self.class_dict[label])\n",
    "\n",
    "        return np.array(bbox), np.array(labels)\n",
    "\n",
    "    def refine_gt(self, graph_dict, bbox):\n",
    "        pos = graph_dict['pos']['spatial']\n",
    "        is_control = graph_dict['attr']['is_control']\n",
    "        #print(pos.shape, bbox.shape, labels.shape)\n",
    "        #print(np.max(pos[:, 0]), np.max(pos[:, 1]))\n",
    "\n",
    "        th = 1e-3\n",
    "        gt_bb = []\n",
    "        gt_cls = []\n",
    "        gt_object = []\n",
    "\n",
    "        for node_idx, p in enumerate(pos):\n",
    "            if is_control[node_idx]: \n",
    "                gt_bb.append((0, 0, 0, 0))\n",
    "                gt_cls.append((0))\n",
    "                gt_object.append((0))\n",
    "                continue\n",
    "\n",
    "            diff_0 = p[None, :] - bbox[:, 0:2]\n",
    "            diff_1 = p[None, :] - bbox[:, 2:]\n",
    "            in_object = (diff_0[:, 0] >= -th) & (diff_0[:, 1] >= -th) & (diff_1[:, 0] <= th) & (diff_1[:, 1] <= th)\n",
    "            \n",
    "            object_index = np.where(in_object)[0]\n",
    "            if len(object_index) > 1:\n",
    "                #print(object_index)\n",
    "                #print('node', p[0] * width, p[1] * height, 'is inside more than one object')\n",
    "                candidates = bbox[object_index]\n",
    "                s = euclidean_distances(p[None, :], candidates[:, 0:2])[0]\n",
    "                #print(np.argsort(s))\n",
    "                object_index = object_index[np.argsort(s)]\n",
    "                #print(candidates, s, object_index)\n",
    "            elif len(object_index) == 0:\n",
    "                #print(diff_0 * [width, height], diff_1* [width, height])\n",
    "                #print(object_index)\n",
    "                print('node', p[0] * width, p[1] * height, 'outside all object')\n",
    "                #for i, line in enumerate(bbox[:, 0:2] * [width, height]):\n",
    "                #    print(i, line)\n",
    "                raise SystemExit\n",
    "            cls = labels[object_index[0]]\n",
    "            bb = bbox[object_index[0]]\n",
    "            '''\n",
    "            h = bb[3] - bb[1]\n",
    "            w = bb[2] - bb[0]\n",
    "            offset_x = bb[0] - p[0]\n",
    "            offset_y = bb[1] - p[1]\n",
    "            gt_bb.append((offset_x, offset_y, w, h))\n",
    "            '''\n",
    "            gt_bb.append(bb)\n",
    "            gt_cls.append(cls)\n",
    "            gt_object.append(object_index[0])\n",
    "        \n",
    "        #assign label to control\n",
    "        control_neighboor = {}\n",
    "        for e in graph_dict['edge']['control']:\n",
    "            #print(is_control[e[0]], is_control[e[1]])\n",
    "            \n",
    "            if not is_control[e[0]] and is_control[e[1]]:\n",
    "                c_node = e[1]\n",
    "                node = e[0]\n",
    "            elif not is_control[e[1]] and is_control[e[0]]:\n",
    "                c_node = e[0]\n",
    "                node = e[1]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "            if c_node not in control_neighboor:\n",
    "                control_neighboor[c_node] = []\n",
    "            control_neighboor[c_node].append(node)\n",
    "        #print(graph_dict['edge']['control'])\n",
    "        #print(control_neighboor)\n",
    "        \n",
    "        #print(gt_bb, gt_cls)\n",
    "        for node_idx, p in enumerate(pos):\n",
    "            if is_control[node_idx]: \n",
    "                #print(control_neighboor[node_idx][0])\n",
    "                gt_bb[node_idx] = gt_bb[control_neighboor[node_idx][0]]\n",
    "                gt_cls[node_idx] = gt_cls[control_neighboor[node_idx][0]]\n",
    "                gt_object[node_idx] = gt_object[control_neighboor[node_idx][0]]\n",
    "                #raise SystemExit\n",
    "        #print(gt_bb, gt_cls)\n",
    "        \n",
    "        return np.array(gt_bb), np.array(gt_cls), np.array(gt_object)\n",
    "\n",
    "    def __transform__(self, pos, scale, angle, translate):\n",
    "        scale_m = np.eye(2)\n",
    "        scale_m[0, 0] = scale\n",
    "        scale_m[1, 1] = scale\n",
    "\n",
    "        rot_m = np.eye(2)\n",
    "        rot_m[0, 0:2] = [np.cos(angle), np.sin(angle)]\n",
    "        rot_m[1, 0:2] = [-np.sin(angle), np.cos(angle)]\n",
    "\n",
    "        #print(pos.shape, scale_m[0:2].shape)\n",
    "        \n",
    "        #print(pos.shape)\n",
    "        center = np.array((0.5, 0.5))[None, :]\n",
    "        pos -= center\n",
    "        if random.choice([True, False]):\n",
    "            pos[:, 0] = -pos[:, 0]\n",
    "        if random.choice([True, False]):\n",
    "            pos[:, 1] = -pos[:, 1]\n",
    "        pos = np.matmul(pos, rot_m[0:2])\n",
    "        pos += center\n",
    "        pos += np.array(translate)[None, :]\n",
    "        pos = np.matmul(pos, scale_m[0:2])\n",
    "        return pos\n",
    "\n",
    "    def __transform_bbox__(self, bbox, scale, angle, translate):\n",
    "        p0 = bbox[:, 0:2]\n",
    "        p2 = bbox[:, 2:]\n",
    "        p1 = np.concatenate([p2[:, 0][:, None], p0[:, 1][:, None]], axis = 1)\n",
    "        p3 = np.concatenate([p0[:, 0][:, None], p2[:, 1][:, None]], axis = 1)\n",
    "        \n",
    "        p0 = self.__transform__(p0, scale, angle, translate)\n",
    "        p1 = self.__transform__(p1, scale, angle, translate)\n",
    "        p2 = self.__transform__(p2, scale, angle, translate)\n",
    "        p3 = self.__transform__(p3, scale, angle, translate)\n",
    "\n",
    "        \n",
    "        def bound_rect(p0, p1, p2, p3):\n",
    "            x = np.concatenate((p0[:, 0][:, None], p1[:, 0][:, None], p2[:, 0][:, None], p3[:, 0][:, None]), axis = 1)\n",
    "            y = np.concatenate((p0[:, 1][:, None], p1[:, 1][:, None], p2[:, 1][:, None], p3[:, 1][:, None]), axis = 1)\n",
    "            x_min = x.min(1, keepdims = True)\n",
    "            x_max = x.max(1, keepdims = True)\n",
    "            y_min = y.min(1, keepdims = True)\n",
    "            y_max = y.max(1, keepdims = True)\n",
    "\n",
    "            return np.concatenate([x_min, y_min, x_max, y_max], axis = 1)\n",
    "        return bound_rect(p0, p1, p2, p3)\n",
    "\n",
    "    def random_transfer(self, pos, bbox, gt_bbox, bbox_targets):\n",
    "        scale_ratio = 0.6\n",
    "        scale = (np.random.random() * 2 - 1) * scale_ratio + 1 #np.random.random() * 0.2 + 0.9\n",
    "        angle = np.random.random() * np.pi * 2\n",
    "\n",
    "        translate_ratio = 0.1\n",
    "        translate = [0, 0]\n",
    "        translate[0] = (np.random.random() * 2 - 1) * translate_ratio #np.random.random() * 0.2 - 0.1\n",
    "        translate[1] = (np.random.random() * 2 - 1) * translate_ratio #np.random.random() * 0.2 - 0.1\n",
    "\n",
    "        pos = self.__transform__(pos, scale, angle, translate)\n",
    "        #bbox = self.__transform_bbox__(bbox, scale, angle, translate)\n",
    "        gt_bbox = self.__transform_bbox__(gt_bbox, scale, angle, translate)\n",
    "        bbox_targets = self.__transform_bbox__(bbox_targets, scale, angle, translate)\n",
    "\n",
    "        return pos, bbox, gt_bbox, bbox_targets\n",
    "\n",
    "    def getEdgeWeight(self, pos, edge):\n",
    "        distance = euclidean_distances(pos, pos)\n",
    "        w = 1 / np.exp(distance)\n",
    "        weight = []\n",
    "\n",
    "        for e in edge:\n",
    "            weight.append(w[e[0], e[1]])\n",
    "        return np.array(weight)\n",
    "\n",
    "    def _get_proposal(self, graph_dict, gt_bbox, gt_labels, bbox_sampling_step = -1):\n",
    "        cc = graph_dict['cc']\n",
    "        pos = graph_dict['pos']['spatial']\n",
    "        edge = graph_dict['edge']['shape']\n",
    "        edge_super = graph_dict['edge']['super']\n",
    "        e_attr = graph_dict['edge_attr']['shape']\n",
    "        e_attr_super = graph_dict['edge_attr']['super']\n",
    "        is_super = graph_dict['attr']['is_super']\n",
    "        is_control = graph_dict['attr']['is_control']\n",
    "        width = graph_dict['img_width']\n",
    "        height = graph_dict['img_height']\n",
    "\n",
    "        #print(pos.shape, is_super.shape, edge.shape, edge_super.shape, e_attr.shape, e_attr_super.shape)\n",
    "        #self.mixup\n",
    "               \n",
    "        o2n = {}\n",
    "        count = 0\n",
    "        for i, ic in enumerate(is_control):\n",
    "            if not ic:\n",
    "                o2n[i] = count\n",
    "                count += 1\n",
    "\n",
    "        new_edge = []\n",
    "        for e in edge:\n",
    "            new_edge.append([o2n[e[0]], o2n[e[1]]])\n",
    "        edge = np.array(new_edge)\n",
    "\n",
    "        new_cc = []\n",
    "        for cluster in cc:\n",
    "            new_cluster = []\n",
    "            for idx in cluster:\n",
    "                new_cluster.append(o2n[idx])\n",
    "            new_cc.append(new_cluster)\n",
    "        cc = new_cc\n",
    "\n",
    "        new_edge = []\n",
    "        for e in edge_super:\n",
    "            new_edge.append([o2n[e[0]], o2n[e[1]]])\n",
    "        edge_super = np.array(new_edge)\n",
    "\n",
    "        not_control = (is_control == 0)[:, 0]\n",
    "        pos = pos[not_control]\n",
    "        is_super = is_super[not_control]\n",
    "        \n",
    "        #print('before mixup', len(cc), pos.shape, edge_super.shape, e_attr_super.shape)\n",
    "        if self.do_mixup:\n",
    "            cc, pos, edge, edge_super, e_attr, e_attr_super, is_super = self.mixup(cc, pos, edge, edge_super, e_attr, e_attr_super, is_super)\n",
    "        #print('after mixup', len(cc), pos.shape, edge_super.shape, e_attr_super.shape)\n",
    "\n",
    "\n",
    "        new_pos = []\n",
    "        new_edge = []\n",
    "        new_edge_super = []\n",
    "        new_e_attr = []\n",
    "        new_e_attr_super = []\n",
    "        new_is_super = []\n",
    "        new_labels = []\n",
    "        new_bbox = []\n",
    "        bbox_targets = []\n",
    "        bbox_idx = []\n",
    "        stat_feats = []\n",
    "        has_objs = []\n",
    "        offset = 0\n",
    "        roots = []\n",
    "        bbox_count = 0\n",
    "\n",
    "        subcluster_slice_pos = [0]\n",
    "        subcluster_slice_edge = [0]\n",
    "        subcluster_slice_super = [0]\n",
    "        subcluster_slice_bbox = [0]\n",
    "\n",
    "        for cc_idx, cluster in enumerate(cc):\n",
    "            #cluster = [i for i in cluster if not is_super[i]]\n",
    "            pos_cluster = pos[cluster, :]\n",
    "            #print(pos_cluster)\n",
    "            \n",
    "            max_x = pos_cluster[:, 0].max(0)\n",
    "            min_x = pos_cluster[:, 0].min(0)\n",
    "            max_y = pos_cluster[:, 1].max(0)\n",
    "            min_y = pos_cluster[:, 1].min(0)\n",
    "\n",
    "            #########################\n",
    "            x_values = sorted(pos_cluster[:, 0])\n",
    "            y_values = sorted(pos_cluster[:, 1])\n",
    "            #print('fooo', x_values, y_values)\n",
    "            def merge_values(values):\n",
    "                new_values  = [values[0]]\n",
    "                for i in range(1, len(values)):\n",
    "                    if values[i] != values[i - 1]: #> 1e-3:\n",
    "                        new_values.append(values[i])\n",
    "                return new_values\n",
    "            x_values = merge_values(x_values)\n",
    "            y_values = merge_values(y_values)\n",
    "            #print(x_values, y_values)\n",
    "\n",
    "            def get_values_dict(values):\n",
    "                values_dict = {}\n",
    "                for i, v in enumerate(values):\n",
    "                    values_dict[v] = i\n",
    "                return values_dict\n",
    "            x_values_dict = get_values_dict(x_values)\n",
    "            y_values_dict = get_values_dict(y_values)\n",
    "\n",
    "            use_bit = False\n",
    "\n",
    "            #point_exist = np.ones((len(y_values), len(x_values))).astype(np.int8) * (-1)\n",
    "            point_exist = [[[] for j in range(len(x_values))] for i in range(len(y_values))]\n",
    "            #print(x_values, y_values)\n",
    "\n",
    "            pos_idx = range(pos_cluster.shape[0])\n",
    "            if use_bit and len(pos_idx) > 64:\n",
    "                print('more than 64 points in cc', len(pos_idx))\n",
    "                pos_idx = random.sample(pos_idx, 64)\n",
    "\n",
    "            for i in pos_idx:\n",
    "                p = pos_cluster[i]                \n",
    "                point_exist[y_values_dict[p[1]]][x_values_dict[p[0]]].append(i)\n",
    "            \n",
    "            def set_bit(value, bit):\n",
    "                return value | (1<<bit)\n",
    "\n",
    "            d00 = [[None for i in range(len(x_values))] for j in range(len(y_values))]\n",
    "            d00[0][0] = point_exist[0][0]\n",
    "\n",
    "            for i in range(1, len(x_values)):\n",
    "                d00[0][i] = d00[0][i - 1] + point_exist[0][i]\n",
    "\n",
    "            for i in range(1, len(y_values)):\n",
    "                d00[i][0] = d00[i - 1][0] + point_exist[i][0]\n",
    "\n",
    "            d_row = [[None for i in range(len(x_values))] for j in range(len(y_values))]\n",
    "            for i in range(0, len(x_values)):\n",
    "                d_row[0][i] = d00[0][i]\n",
    "\n",
    "            for i in range(1, len(y_values)):\n",
    "                d_row[i][0] = point_exist[i][0]\n",
    " \n",
    "            for y in range(1, len(y_values)):\n",
    "                for x in range(1, len(x_values)):\n",
    "                    d_row[y][x] = d_row[y][x - 1] + point_exist[y][x]\n",
    "                    d00[y][x] = d00[y - 1][x] + d_row[y][x]\n",
    "            \n",
    "            for y in range(0, len(y_values)):\n",
    "                for x in range(0, len(x_values)):\n",
    "                    d00[y][x] = set(d00[y][x])\n",
    "\n",
    "            sub_clusters = []\n",
    "            #print(len(y_values),len(x_values))\n",
    "\n",
    "            \n",
    "            x_step = (max_x - min_x) / bbox_sampling_step #10 #5 #5#25\n",
    "            y_step = (max_y - min_y) / bbox_sampling_step #10 #5 #5\n",
    "            #print('x_step', x_step, 'y_step', y_step)\n",
    "            #print(d00)\n",
    "\n",
    "            x_grids = np.arange(min_x, max_x, x_step)\n",
    "            y_grids = np.arange(min_y, max_y, y_step)\n",
    "\n",
    "\n",
    "            x_grids = np.append(x_grids, max_x)\n",
    "            y_grids = np.append(y_grids, max_y)\n",
    "\n",
    "            #print(x_grids, y_grids)\n",
    "            def move_endpoint(x, values, bound):\n",
    "                if x >= len(values):\n",
    "                    return x - 1\n",
    "\n",
    "                while values[x] <= bound:\n",
    "                    x += 1\n",
    "                    if x >= len(values):\n",
    "                        break\n",
    "                return x - 1\n",
    "\n",
    "            def move_endpoint_close(x, values, bound):\n",
    "                if x >= len(values):\n",
    "                    return x - 1\n",
    "\n",
    "                while values[x] < bound:\n",
    "                    x += 1\n",
    "                    if x >= len(values):\n",
    "                        break\n",
    "                return x - 1\n",
    "            \n",
    "            prev_y0 = -1\n",
    "            grid_y0 = 0\n",
    "            for i_grid_y0, grid_y0 in enumerate(y_grids):\n",
    "                y0 = move_endpoint_close(prev_y0 + 1, y_values, grid_y0)\n",
    "                if y0 != len(y_values): y0 += 1\n",
    "                if y0 == prev_y0: continue\n",
    "                prev_y0 = y0\n",
    "                \n",
    "                grid_x0 = x_values[0]\n",
    "                prev_x0 = -1\n",
    "                for i_grid_x0, grid_x0 in enumerate(x_grids):\n",
    "                    x0 = move_endpoint_close(prev_x0 + 1, x_values, grid_x0)\n",
    "                    if x0 != len(y_values): x0 += 1\n",
    "                    if x0 == prev_x0: continue\n",
    "                    prev_x0 = x0\n",
    "                    \n",
    "                    #grid_y1 = grid_y0\n",
    "                    prev_y1 = y0\n",
    "                    for grid_y1 in y_grids[i_grid_y0 + 1 :]:\n",
    "                        y1 = move_endpoint(prev_y1 + 1, y_values, grid_y1)\n",
    "                        #if prev_y1 + 1 < len(y_values):\n",
    "                        #    print(prev_y1 + 1, y_values[prev_y1 + 1], 'to', grid_y1)\n",
    "                        if y1 == prev_y1: continue\n",
    "                        #print('---------------', prev_y1, 'to', y1, y_values[prev_y1], 'to', grid_y1)\n",
    "                        prev_y1 = y1\n",
    "                        \n",
    "                        #grid_x1 = grid_x0\n",
    "                        prev_x1 = x0\n",
    "                        for grid_x1 in x_grids[i_grid_x0 + 1:]:\n",
    "                            x1 = move_endpoint(prev_x1 + 1, x_values, grid_x1)\n",
    "                            if x1 == prev_x1: continue\n",
    "                            prev_x1 = x1\n",
    "                            \n",
    "                            if use_bit:\n",
    "                                if x0 > 0 and y0 > 0:\n",
    "                                    dd = d00[y1][x1] - (d00[y1][x0 - 1] | d00[y0 - 1][x1])\n",
    "                                elif x0 > 0 and y0 == 0:\n",
    "                                    dd = d00[y1][x1] - d00[y1][x0 - 1]\n",
    "                                elif y0 > 0 and x0 == 0:\n",
    "                                    dd = d00[y1][x1] - d00[y0 - 1][x1]\n",
    "                                else:\n",
    "                                    dd = d00[y1][x1]\n",
    "                                if dd == 0: continue\n",
    "                                count = 0\n",
    "                                sub_c = []\n",
    "                                while dd != 0:\n",
    "                                    if dd & 1:\n",
    "                                        sub_c.append(count)\n",
    "                                    count += 1\n",
    "                                    dd = dd >> 1\n",
    "                                sub_c = [cluster[ii] for ii in sub_c]\n",
    "                                sub_clusters.append(tuple(sub_c))\n",
    "                            else:\n",
    "                                if x0 > 0 and y0 > 0:\n",
    "                                    dd = d00[y1][x1].difference(d00[y1][x0 - 1]).difference(d00[y0 - 1][x1])\n",
    "                                elif x0 > 0 and y0 == 0:\n",
    "                                    dd = d00[y1][x1].difference(d00[y1][x0 - 1])\n",
    "                                elif y0 > 0 and x0 == 0:\n",
    "                                    dd = d00[y1][x1].difference(d00[y0 - 1][x1])\n",
    "                                else:\n",
    "                                    dd = d00[y1][x1]\n",
    "                                #print(x0, y0, x1, y1, 'fooo')\n",
    "                                sub_c = [cluster[ii] for ii in dd]\n",
    "                                sub_clusters.append(tuple(sorted(sub_c)))\n",
    "            \n",
    "            sub_clusters = list(set(sub_clusters))\n",
    "            \n",
    "            #########################\n",
    "            def get_adj(edge):\n",
    "                #adj = -np.ones((pos.shape[0], pos.shape[0])).astype(np.int)\n",
    "                adj = [[[] for j in range(pos.shape[0])] for j in range(pos.shape[0])]\n",
    "                for i, e in enumerate(edge):\n",
    "                    #adj[e[0], e[1]] = i\n",
    "                    #adj[e[1], e[0]] = i\n",
    "                    adj[e[0]][e[1]].append(i)\n",
    "                    adj[e[1]][e[0]].append(i)\n",
    "                return adj\n",
    "            \n",
    "            A = get_adj(edge)\n",
    "            A_super = get_adj(edge_super)\n",
    "            #print(A)\n",
    "\n",
    "            bbox_cc = np.array([min_x, min_y, max_x, max_y])[None, :]\n",
    "            gt_bbox_idx_valid = intersect_bb_idx(bbox_cc, gt_bbox)\n",
    "            if gt_bbox_idx_valid.shape[0] == 0:\n",
    "                print('cc has no intersect gt bbox')\n",
    "                raise SystemExit\n",
    "\n",
    "            sub_bbox_n = 0\n",
    "            for idxs in sub_clusters:\n",
    "                o2n = {}\n",
    "                for i, idx in enumerate(idxs):\n",
    "                    o2n[idx] = i\n",
    "                pos_bbox = pos[idxs, :]\n",
    "                is_super_bbox = is_super[idxs, :]\n",
    "                #idxs = set(idxs)\n",
    "                \n",
    "                edge_idxs = []\n",
    "                for i in range(len(idxs)):\n",
    "                    for j in range(i + 1, len(idxs)):\n",
    "                        #if A[idxs[i], idxs[j]] >= 0:\n",
    "                            #edge_idxs.append(A[idxs[i], idxs[j]])\n",
    "                        edge_idxs+= A[idxs[i]][idxs[j]]\n",
    "\n",
    "                edge_bbox = edge[edge_idxs]\n",
    "                if edge_bbox.shape[0] == 0:\n",
    "                    continue\n",
    "                #print(edge_bbox)\n",
    "                edge_bbox = np.array([[o2n[e[0]] + offset, o2n[e[1]] + offset] for e in edge_bbox])\n",
    "                e_attr_bbox = e_attr[edge_idxs]\n",
    "                \n",
    "                edge_idxs = []\n",
    "                for i in range(len(idxs)):\n",
    "                    for j in range(i + 1, len(idxs)):\n",
    "                        #if A_super[idxs[i], idxs[j]] >= 0:\n",
    "                            #edge_idxs.append(A_super[idxs[i], idxs[j]])\n",
    "                        edge_idxs += A_super[idxs[i]][idxs[j]]\n",
    "                \n",
    "                edge_super_bbox = edge_super[edge_idxs]\n",
    "                edge_super_bbox = np.array([[o2n[e[0]] + offset, o2n[e[1]] + offset] for e in edge_super_bbox])\n",
    "                e_attr_super_bbox = e_attr_super[edge_idxs]\n",
    "                \n",
    "                #print(count, offset, pos_bbox.shape, is_super_bbox.shape, edge_bbox.shape, edge_super_bbox.shape, e_attr_bbox.shape, e_attr_super_bbox.shape)\n",
    "\n",
    "                max_x = pos_bbox[:, 0].max(0)\n",
    "                min_x = pos_bbox[:, 0].min(0)\n",
    "                max_y = pos_bbox[:, 1].max(0)\n",
    "                min_y = pos_bbox[:, 1].min(0)\n",
    "                                \n",
    "                if max_x - min_x < 1e-4 or max_y - min_y < 1e-4:\n",
    "                    continue\n",
    "                    \n",
    "                proposal = np.array([min_x, min_y, max_x, max_y])[None, :]\n",
    "                iou, ios = bbox_iou_ios_cpu(proposal, gt_bbox[gt_bbox_idx_valid, :])\n",
    "                idx_gt = np.argmax(iou)\n",
    "                \n",
    "                \n",
    "                if iou[idx_gt] > 0.7:\n",
    "                    label = gt_labels[gt_bbox_idx_valid[idx_gt]]                    \n",
    "                    bbox_target = gt_bbox[gt_bbox_idx_valid[idx_gt]][None, :]\n",
    "\n",
    "                else:\n",
    "                    label = self.n_classes - 1\n",
    "                    bbox_target = np.zeros((1, 4))\n",
    "\n",
    "                idx_gt = np.argmax(iou)\n",
    "                if ios[idx_gt] > 0.7:\n",
    "                    has_obj = 1\n",
    "                else:\n",
    "                    has_obj = 0\n",
    "                \n",
    "                \n",
    "                ######################obtain stats#################################\n",
    "                stats = []\n",
    "                n_points = pos_bbox.shape[0]\n",
    "                n_edges = edge_bbox.shape[0]\n",
    "                \n",
    "                n_angle_less90 = 0\n",
    "                n_angle_90 = 0\n",
    "                n_angle_more90 = 0\n",
    "                adj = [set() for i in range(pos.shape[0])]\n",
    "\n",
    "                for e in edge_bbox:\n",
    "                    adj[e[0] - offset].add(e[1] - offset)\n",
    "                    adj[e[1] - offset].add(e[0] - offset)\n",
    "                    \n",
    "                angles = []\n",
    "                for anchor, neighbors in enumerate(adj):\n",
    "                    neighbors = list(neighbors)\n",
    "                    for i in range(len(neighbors)):\n",
    "                        for j in range(i + 1, len(neighbors)):\n",
    "                            p0 = pos_bbox[neighbors[i]]\n",
    "                            p1 = pos_bbox[neighbors[j]]\n",
    "                            p_anchor = pos_bbox[anchor]\n",
    "                            v0 = p0 - p_anchor\n",
    "                            v1 = p1 - p_anchor\n",
    "\n",
    "                            dot = v0[0] * v1[0] + v0[1] * v1[1]\n",
    "                            if dot <= -1e-2:\n",
    "                                n_angle_more90 += 1\n",
    "                            elif dot >= 1e-2:\n",
    "                                n_angle_less90 += 1\n",
    "                            elif np.abs(dot) < 1e-2:\n",
    "                                n_angle_90 +=1\n",
    "                            angles.append(dot)\n",
    "                            \n",
    "                width = max_x - min_x\n",
    "                height = max_y - min_y\n",
    "\n",
    "                if len(angles) == 0:\n",
    "                    continue\n",
    "                \n",
    "                angles = np.array(angles)\n",
    "                mean_angle = np.mean(angles)\n",
    "                max_angle = np.max(angles)\n",
    "                min_angle = np.min(angles)\n",
    "                std_angle = np.std(angles)\n",
    "\n",
    "                long_short_ratio = max(width, height) * 1.0 / min(width, height)\n",
    "\n",
    "                mean_edge_distance = np.mean(e_attr_bbox[:, -1])\n",
    "                std_edge_distance = np.std(e_attr_bbox[:, -1])\n",
    "                mean_edge_angle = np.mean(e_attr_bbox[:, -2])\n",
    "                std_edge_angle = np.std(e_attr_bbox[:, -2])\n",
    "\n",
    "                '''\n",
    "                stat_feat = np.array([n_points, n_edges, n_angle_90, n_angle_less90, n_angle_more90, \n",
    "                    width, height, mean_angle, max_angle, min_angle, std_angle, mean_edge_angle, \n",
    "                    std_edge_angle, mean_edge_distance, std_edge_distance])[None, :]\n",
    "                    #, long_short_ratio])[None, :]\n",
    "                '''\n",
    "                \n",
    "                stat_feat = np.array([n_points, n_edges, n_angle_90, n_angle_less90, n_angle_more90, \n",
    "                    width, height, mean_angle, max_angle, min_angle, std_angle, mean_edge_distance, std_edge_distance])[None, :]\n",
    "\n",
    "                if self.normalize_bbox:\n",
    "                    '''\n",
    "                    if max_x - min_x >  max_y - min_y:\n",
    "                        pos_bbox = (pos_bbox - [min_x, min_y]) / [max_x - min_x, max_x - min_x]\n",
    "                    else:\n",
    "                        pos_bbox = (pos_bbox - [min_x, min_y]) / [max_y - min_y, max_y - min_y]\n",
    "                    '''\n",
    "                    pos_bbox = (pos_bbox - [min_x, min_y]) / [max_x - min_x, max_y - min_y]\n",
    "                \n",
    "\n",
    "                subcluster_slice_pos.append(subcluster_slice_pos[-1] + pos_bbox.shape[0])\n",
    "                subcluster_slice_edge.append(subcluster_slice_edge[-1] + edge_bbox.shape[0])\n",
    "                subcluster_slice_super.append(subcluster_slice_super[-1] + edge_super_bbox.shape[0])\n",
    "                subcluster_slice_bbox.append(subcluster_slice_bbox[-1] + 1)\n",
    "\n",
    "                new_pos.append(pos_bbox)\n",
    "                new_is_super.append(is_super_bbox)\n",
    "                if edge_bbox.shape[0] > 0:\n",
    "                    new_edge.append(edge_bbox)\n",
    "                if edge_super_bbox.shape[0] > 0:\n",
    "                    new_edge_super.append(edge_super_bbox)\n",
    "                new_e_attr.append(e_attr_bbox)\n",
    "                new_e_attr_super.append(e_attr_super_bbox)\n",
    "                new_labels.append(label)\n",
    "                has_objs.append(has_obj)\n",
    "                bbox_idx += [bbox_count] * pos_bbox.shape[0]\n",
    "                offset += pos_bbox.shape[0]\n",
    "                new_bbox.append([min_x, min_y, max_x, max_y])\n",
    "                bbox_targets.append(bbox_target)\n",
    "                stat_feats.append(stat_feat)\n",
    "\n",
    "                sub_bbox_n += 1\n",
    "                bbox_count += 1\n",
    "\n",
    "            #print(sub_bbox_n, subcluster_slice_pos, subcluster_slice_edge, subcluster_slice_super, subcluster_slice_bbox)\n",
    "            \n",
    "            idx_offset = len(subcluster_slice_bbox) - sub_bbox_n - 1\n",
    "            sub_bbox = np.array(new_bbox)[subcluster_slice_bbox[idx_offset]:]\n",
    "            #print(sub_bbox, sub_bbox.shape)\n",
    "            area = (sub_bbox[:, 2] - sub_bbox[:, 0]) * (sub_bbox[:, 3] - sub_bbox[:, 1])\n",
    "            #print(area)\n",
    "            max_idx = np.argmax(area)\n",
    "            #print('root idx', max_idx)\n",
    "            root = idxTree()\n",
    "            root.value['idx_pos'] = (subcluster_slice_pos[idx_offset + max_idx], subcluster_slice_pos[idx_offset + max_idx + 1])\n",
    "            root.value['idx_edge'] = (subcluster_slice_edge[idx_offset + max_idx], subcluster_slice_edge[idx_offset + max_idx + 1])\n",
    "            root.value['idx_edge_super'] = (subcluster_slice_super[idx_offset + max_idx], subcluster_slice_super[idx_offset + max_idx + 1])\n",
    "            root.value['idx_bbox'] = subcluster_slice_bbox[idx_offset + max_idx]\n",
    "\n",
    "            #print(root.value)\n",
    "\n",
    "            #print(subcluster_slice_pos, len(bbox_idx))\n",
    "            for i in range(sub_bbox.shape[0]):\n",
    "                if i == max_idx: continue\n",
    "                p = idxTree()\n",
    "                p.value['idx_pos'] = (subcluster_slice_pos[idx_offset + i], subcluster_slice_pos[idx_offset + i + 1])\n",
    "                p.value['idx_edge'] = (subcluster_slice_edge[idx_offset + i], subcluster_slice_edge[idx_offset + i + 1])\n",
    "                p.value['idx_edge_super'] = (subcluster_slice_super[idx_offset + i], subcluster_slice_super[idx_offset + i + 1])\n",
    "                p.value['idx_bbox'] = subcluster_slice_bbox[idx_offset + i]\n",
    "                root.children.append(p)\n",
    "            #print(subcluster_slice_pos, subcluster_slice_edge, subcluster_slice_super, subcluster_slice_bbox)\n",
    "            roots.append(root)\n",
    "            \n",
    "            #print(len(bbox_idx), np.concatenate(new_pos, axis = 0).shape)\n",
    "            #raise SystemExit\n",
    "\n",
    "        pos = np.concatenate(new_pos, axis = 0)\n",
    "        is_super = np.concatenate(new_is_super, axis = 0)\n",
    "        edge = np.concatenate(new_edge, axis = 0)\n",
    "        edge_super = np.concatenate(new_edge_super, axis = 0)\n",
    "        e_attr = np.concatenate(new_e_attr, axis = 0)\n",
    "        e_attr_super = np.concatenate(new_e_attr_super, axis = 0)\n",
    "        labels = new_labels\n",
    "        new_bbox = np.array(new_bbox)\n",
    "        bbox_targets = np.concatenate(bbox_targets, axis = 0)\n",
    "        bbox_idx = np.array(bbox_idx)\n",
    "        is_control = np.zeros((pos.shape[0], 1))\n",
    "        stat_feats = np.concatenate(stat_feats, axis = 0)\n",
    "        has_obj = has_objs\n",
    "        #print(pos.shape, is_super.shape, edge.shape, edge_super.shape, e_attr.shape, e_attr_super.shape)\n",
    "        #print(pos.shape)\n",
    "\n",
    "        return pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, new_bbox, bbox_targets, stat_feats, has_obj, roots\n",
    "\n",
    "    def mixup(self, cc, pos, edge, edge_super, e_attr, e_attr_super, is_super):\n",
    "        cc_idx = [0 for i in range(len(pos))] \n",
    "        cc_edge = [[] for i in range(len(cc))]\n",
    "        cc_edge_super = [[] for i in range(len(cc))]\n",
    "        cc_e_attr = [[] for i in range(len(cc))]\n",
    "        \n",
    "        for cluster_i, cluster in enumerate(cc):\n",
    "            for idx in cluster:\n",
    "                cc_idx[idx] = cluster_i\n",
    "        for e, a in zip(edge, e_attr):\n",
    "            cc_edge[cc_idx[e[0]]].append(e)\n",
    "            cc_e_attr[cc_idx[e[0]]].append(a)\n",
    "        \n",
    "        for e in edge_super:\n",
    "            cc_edge_super[cc_idx[e[0]]].append(e)\n",
    "\n",
    "        grouped_idx = [[] for i in range(len(cc))]\n",
    "        offset = pos.shape[0]\n",
    "\n",
    "        new_cc = []\n",
    "        new_pos = []\n",
    "        new_edge = []\n",
    "        new_edge_super = []\n",
    "        new_e_attr = []\n",
    "        new_e_attr_super = []\n",
    "        new_is_super = []\n",
    "\n",
    "        def normalize_pos(pos):\n",
    "            max_x = pos[:, 0].max(0)\n",
    "            min_x = pos[:, 0].min(0)\n",
    "            max_y = pos[:, 1].max(0)\n",
    "            min_y = pos[:, 1].min(0)\n",
    "            \n",
    "            if max_x - min_x >  max_y - min_y:\n",
    "                pos = (pos - [min_x, min_y]) / [max_x - min_x, max_x - min_x]\n",
    "            else:\n",
    "                pos = (pos - [min_x, min_y]) / [max_y - min_y, max_y - min_y]\n",
    "            return pos\n",
    "        \n",
    "        def update_edge_idx(edge, old_idx, new_idx):\n",
    "            o2n = {}\n",
    "            for i, j in zip(old_idx, new_idx):\n",
    "                o2n[i] = j\n",
    "            new_edge = []\n",
    "            for e in edge:\n",
    "                new_edge.append([o2n[e[0]], o2n[e[1]]])\n",
    "            #print(o2n)\n",
    "            return np.array(new_edge)\n",
    "\n",
    "        for cluster_i in range(len(cc)):\n",
    "            cluster_j = random.choice(range(len(cc)))\n",
    "            cluster = cc[cluster_i]\n",
    "            cluster_shuffled = cc[cluster_j]\n",
    "            \n",
    "            pos_bb0 = pos[cluster]\n",
    "            pos_bb1 = pos[cluster_shuffled]\n",
    "\n",
    "            edge_bb0 = np.stack(cc_edge[cluster_i])\n",
    "            edge_bb1 = np.stack(cc_edge[cluster_j])\n",
    "            edge_super_bb0 = np.stack(cc_edge_super[cluster_i])\n",
    "            edge_super_bb1 = np.stack(cc_edge_super[cluster_j])\n",
    "\n",
    "            e_attr_bb0 = np.stack(cc_e_attr[cluster_i])\n",
    "            e_attr_bb1 = np.stack(cc_e_attr[cluster_j])\n",
    "            \n",
    "            pos_bb0 = normalize_pos(pos_bb0)\n",
    "            pos_bb1 = normalize_pos(pos_bb1)\n",
    "\n",
    "            right = random.choice([True, False])\n",
    "            if right:\n",
    "                translate_x = 1 + np.random.random() * 0.1\n",
    "                translate_y = np.random.random()\n",
    "                pos_bb1[:, 0] += translate_x\n",
    "                pos_bb1[:, 1] += translate_y\n",
    "            else:\n",
    "                translate_x = np.random.random()\n",
    "                translate_y = 1 +  0.1 * np.random.random()\n",
    "                pos_bb1[:, 0] += translate_x\n",
    "                pos_bb1[:, 1] += translate_y\n",
    "\n",
    "            pos_merged = np.concatenate([pos_bb0, pos_bb1], axis = 0)\n",
    "            is_super_merged = np.concatenate([is_super[cluster], is_super[cluster_shuffled]], axis = 0)\n",
    "\n",
    "            idx_bb0 = offset + np.arange(len(cluster))\n",
    "            idx_bb1 = offset + len(cluster) + np.arange(len(cluster_shuffled))\n",
    "            #print(idx_bb0, idx_bb1)\n",
    "            idx_merged = list(idx_bb0) + list(idx_bb1)\n",
    "            edge_super_merged = []\n",
    "            for i in idx_bb0:\n",
    "                for j in idx_bb1:\n",
    "                    edge_super_merged.append([i, j])\n",
    "            \n",
    "            edge_bb0 = update_edge_idx(edge_bb0, cluster, idx_bb0)\n",
    "            edge_bb1 = update_edge_idx(edge_bb1, cluster_shuffled, idx_bb1)\n",
    "            edge_super_bb0 = update_edge_idx(edge_super_bb0, cluster, idx_bb0)\n",
    "            edge_super_bb1 = update_edge_idx(edge_super_bb1, cluster_shuffled, idx_bb1)\n",
    "\n",
    "            new_pos.append(pos_merged)\n",
    "            new_cc.append(idx_merged)\n",
    "            new_edge.append(np.concatenate([edge_bb0, edge_bb1], axis = 0))\n",
    "            new_edge_super.append(np.concatenate([edge_super_bb0, edge_super_bb1, edge_super_merged], axis = 0))\n",
    "            new_e_attr.append(np.concatenate([e_attr_bb0, e_attr_bb1], axis = 0))\n",
    "            new_e_attr_super.append(np.zeros((edge_super_bb0.shape[0] + edge_super_bb1.shape[0] + len(edge_super_merged), 6)))\n",
    "            new_is_super.append(is_super_merged)\n",
    "\n",
    "\n",
    "            offset += (len(cluster) + len(cluster_shuffled))\n",
    "        \n",
    "        cc = cc + new_cc\n",
    "        pos = np.concatenate([pos] + new_pos, axis = 0)\n",
    "        is_super = np.concatenate([is_super] + new_is_super, axis = 0)\n",
    "        edge = np.concatenate([edge] + new_edge, axis = 0)\n",
    "        edge_super = np.concatenate([edge_super] + new_edge_super, axis = 0)\n",
    "        e_attr = np.concatenate([e_attr] + new_e_attr, axis = 0)\n",
    "        e_attr_super = np.concatenate([e_attr_super] + new_e_attr_super, axis = 0)\n",
    "\n",
    "        return cc, pos, edge, edge_super, e_attr, e_attr_super, is_super\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        filepath = self.svg_list[idx]\n",
    "        #filepath = '/home/xinyangjiang/Datasets/SESYD/FloorPlans/floorplans16-06/file_97.svg'\n",
    "        #print(filepath)\n",
    "        \n",
    "        \n",
    "        graph_dict = pickle.load(open(filepath.replace('.svg', '.pkl'), 'rb'))\n",
    "        width, height = graph_dict['img_width'], graph_dict['img_height']\n",
    "        \n",
    "        gt_bbox, gt_labels = self._get_bbox(filepath, width, height)\n",
    "        filename_bbox = filepath.replace('.svg', self.bbox_file_postfix)\n",
    "        preload = True\n",
    "        if preload:            \n",
    "            try:\n",
    "                pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, bbox, bbox_targets,stat_feats, has_obj, roots = pickle.load(open(filename_bbox, 'rb'))\n",
    "            except:\n",
    "                #if not os.path.exists(filename_bbox):\n",
    "                pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, bbox, bbox_targets, stat_feats, has_obj, roots = self._get_proposal(graph_dict, gt_bbox, gt_labels, bbox_sampling_step = self.bbox_sampling_step)\n",
    "                pickle.dump([pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, bbox, bbox_targets, stat_feats, has_obj, roots], open(filename_bbox, 'wb'))\n",
    "        else:\n",
    "            pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, bbox, bbox_targets, stat_feats, has_obj, roots = self._get_proposal(graph_dict, gt_bbox, gt_labels, bbox_sampling_step = self.bbox_sampling_step)\n",
    "            pickle.dump([pos, is_super, is_control, edge, edge_super, e_attr, e_attr_super, labels, bbox_idx, bbox, bbox_targets, stat_feats, has_obj, roots], open(filename_bbox, 'wb'))\n",
    "\n",
    "        def update_bbox(pos, bbox_idx):\n",
    "            #print(pos.shape, bbox_idx.shape)\n",
    "            idx = [0]\n",
    "            bbox = []\n",
    "            for i in range(1, len(bbox_idx)):\n",
    "                if bbox_idx[i] != bbox_idx[i - 1]:\n",
    "                    pos_bbox = pos[idx, :]\n",
    "                    max_x = pos_bbox[:, 0].max(0)\n",
    "                    min_x = pos_bbox[:, 0].min(0)\n",
    "                    max_y = pos_bbox[:, 1].max(0)\n",
    "                    min_y = pos_bbox[:, 1].min(0)\n",
    "                    bbox.append([min_x, min_y, max_x, max_y])\n",
    "                    idx = [i]\n",
    "                else:\n",
    "                    idx.append(i)\n",
    "            pos_bbox = pos[idx, :]\n",
    "            max_x = pos_bbox[:, 0].max(0)\n",
    "            min_x = pos_bbox[:, 0].min(0)\n",
    "            max_y = pos_bbox[:, 1].max(0)\n",
    "            min_y = pos_bbox[:, 1].min(0)\n",
    "            bbox.append([min_x, min_y, max_x, max_y])\n",
    "            return np.array(bbox)\n",
    "\n",
    "        if self.data_aug:\n",
    "            pos, bbox, gt_bbox, bbox_targets = self.random_transfer(pos, bbox, gt_bbox, bbox_targets)\n",
    "            bbox = update_bbox(pos, bbox_idx)\n",
    "            #print(bbox)\n",
    "            #print(bbox_targets)\n",
    "            #print()\n",
    "            #raise SystemExit\n",
    "    \n",
    "\n",
    "        feats = np.concatenate((\n",
    "            np.zeros((pos.shape[0], 3)),\n",
    "            pos), \n",
    "            axis = 1)\n",
    "\n",
    "        e_attr = e_attr[:, 0:4]\n",
    "        e_attr_super = e_attr_super[:, 0:4]\n",
    "\n",
    "        #e_weight = self.getEdgeWeight(pos, edge)\n",
    "        #e_weight_super = self.getEdgeWeight(pos, edge_super)\n",
    "\n",
    "\n",
    "        if True:\n",
    "            cc_idx = bbox_idx\n",
    "            cc = [[] for i in range(len(bbox))]\n",
    "            for p_i, b_i in enumerate(bbox_idx):\n",
    "                cc[b_i].append(p_i)\n",
    "\n",
    "            cc_edge = [[] for i in range(len(bbox))]           \n",
    "            for e in edge:\n",
    "                #print(cc_idx[e[0]], cc_idx[e[1]], a)\n",
    "                #print(e, a)\n",
    "                cc_edge[cc_idx[e[0]]].append(e)\n",
    "            \n",
    "            cc_edge_super = [[] for i in range(len(bbox))]           \n",
    "            for e in edge_super:\n",
    "                #print(cc_idx[e[0]], cc_idx[e[1]], a)\n",
    "                #print(e, a)\n",
    "                cc_edge_super[cc_idx[e[0]]].append(e)\n",
    "\n",
    "\n",
    "            for bbox_i, (bbox_pos_idxs, bbox_edge, bbox_edge_super) in enumerate(zip(cc, cc_edge, cc_edge_super)):\n",
    "                bbox_pos = pos[bbox_pos_idxs, :]\n",
    "\n",
    "                print('draw graph', filepath)\n",
    "                img = np.ones((math.ceil(height), math.ceil(width), 3)).astype(np.uint8) * 255\n",
    "                for e in bbox_edge:\n",
    "                    cv2.line(img, \n",
    "                        (int(pos[e[0], 0] * width), int(pos[e[0], 1] * height)), \n",
    "                        (int(pos[e[1], 0] * width), int(pos[e[1], 1] * height)), \n",
    "                        (255, 0, 0), \n",
    "                        5\n",
    "                    )\n",
    "                for e in bbox_edge_super:\n",
    "                    cv2.line(img, \n",
    "                        (int(pos[e[0], 0] * width), int(pos[e[0], 1] * height)), \n",
    "                        (int(pos[e[1], 0] * width), int(pos[e[1], 1] * height)), \n",
    "                        (0, 255, 0), \n",
    "                        2\n",
    "                    )\n",
    "                for i, p in enumerate(bbox_pos):\n",
    "                    if is_super[i]:\n",
    "                        cv2.circle(img,  \n",
    "                            (int(p[0] * width), int(p[1] * height)), \n",
    "                            15, \n",
    "                            (0, 255, 0), \n",
    "                            3\n",
    "                        )\n",
    "                    else:\n",
    "                        cv2.circle(img,  \n",
    "                            (int(p[0] * width), int(p[1] * height)), \n",
    "                            15, \n",
    "                            (255, 0, 0), \n",
    "                            3\n",
    "                        )\n",
    "                \n",
    "                '''\n",
    "                for i in range(labels.shape[0]):\n",
    "                    pos_bbox = pos[bbox_idx == i, :]\n",
    "                    max_x = int(pos_bbox[:, 0].max(0) * width)\n",
    "                    min_x = int(pos_bbox[:, 0].min(0) * width)\n",
    "                    max_y = int(pos_bbox[:, 1].max(0) * height)\n",
    "                    min_y = int(pos_bbox[:, 1].min(0) * height)\n",
    "                    c = tuple(np.random.randint(0, 255, 3).astype(np.uint8))\n",
    "                    print(c)\n",
    "                    cv2.rectangle(img, (min_x, min_y), (max_x, max_y), (int(c[0]), int(c[1]), int(c[2])), 2)\n",
    "                    cv2.putText(img, '%d'%(labels[i]), (min_x, min_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (int(c[0]), int(c[1]), int(c[2])), 2, cv2.LINE_AA)\n",
    "                '''\n",
    "                outname = os.path.dirname(filepath).split('/')[-1] + '_' + os.path.basename(filepath).replace('.svg', '') + '_%d_label%d'%(bbox_i, labels[bbox_i]) + '.png'\n",
    "                outname = os.path.join('vis_debug2', outname)\n",
    "                cv2.imwrite(outname, img)\n",
    "\n",
    "\n",
    "        feats = torch.tensor(feats, dtype=torch.float32)\n",
    "        pos = torch.tensor(pos, dtype=torch.float32)\n",
    "        edge = torch.tensor(edge, dtype=torch.long)\n",
    "        edge_super = torch.tensor(edge_super, dtype=torch.long)\n",
    "        is_control = torch.tensor(is_control, dtype=torch.bool)\n",
    "        is_super = torch.tensor(is_super, dtype=torch.bool)\n",
    "        bbox_targets = torch.tensor(bbox_targets, dtype=torch.float32)\n",
    "        bbox = torch.tensor(bbox, dtype=torch.float32)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        has_obj = torch.tensor(has_obj, dtype=torch.long)\n",
    "        gt_bbox = torch.tensor(gt_bbox, dtype=torch.float32)\n",
    "        gt_labels = torch.tensor(gt_labels, dtype=torch.long)\n",
    "        #e_weight = torch.tensor(e_weight, dtype=torch.float32)\n",
    "        #e_weight_super = torch.tensor(e_weight_super, dtype=torch.float32)\n",
    "        bbox_idx = torch.tensor(bbox_idx, dtype=torch.long)\n",
    "        stat_feats = torch.tensor(stat_feats, dtype=torch.float32)\n",
    "        e_attr = torch.tensor(e_attr, dtype=torch.float32)\n",
    "        e_attr_super = torch.tensor(e_attr_super, dtype=torch.float32)\n",
    "\n",
    "        #e_attr_super = torch.zeros((edge_super.size(0), 4), dtype=torch.float32)\n",
    "\n",
    "        data = Data(x = feats, pos = pos)\n",
    "        data.edge = edge\n",
    "        data.edge_super = edge_super\n",
    "        data.is_control = is_control\n",
    "        data.is_super = is_super\n",
    "        data.bbox = bbox\n",
    "        data.bbox_targets = bbox_targets\n",
    "        data.labels = labels\n",
    "        data.gt_bbox = gt_bbox\n",
    "        data.gt_labels = gt_labels\n",
    "        data.filepath = filepath\n",
    "        data.width = width\n",
    "        data.height = height\n",
    "        data.e_attr = e_attr\n",
    "        data.e_attr_super = e_attr_super\n",
    "        data.bbox_idx = bbox_idx\n",
    "        data.stat_feats = stat_feats\n",
    "        data.has_obj = has_obj\n",
    "        data.roots = roots\n",
    "        #data.e_weight = e_weight\n",
    "        #data.e_weight_super = e_weight_super\n",
    "    \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ottos\\akariinc\\YOLaT-VectorGraphicsRecognition\n"
     ]
    }
   ],
   "source": [
    "%cd C:\\\\Users\\\\ottos\\\\akariinc\\\\YOLaT-VectorGraphicsRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n",
      "draw graph data/FloorPlansGraph5_iter\\floorplans16-01/file_13.svg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mセル9 を c:\\Users\\ottos\\akariinc\\YOLaT-VectorGraphicsRecognition\\dataflow.ipynb\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m CADDataset(opt\u001b[39m.\u001b[39mdata_dir, opt, partition \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, data_aug \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, do_mixup \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, drop_edge \u001b[39m=\u001b[39m opt\u001b[39m.\u001b[39mdrop_edge, bbox_sampling_step \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_dataset[\u001b[39m0\u001b[39;49m]\n",
      "\u001b[1;32mセル9 を c:\\Users\\ottos\\akariinc\\YOLaT-VectorGraphicsRecognition\\dataflow.ipynb\u001b[0m in \u001b[0;36mCADDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=987'>988</a>\u001b[0m bbox_pos \u001b[39m=\u001b[39m pos[bbox_pos_idxs, :]\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=989'>990</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mdraw graph\u001b[39m\u001b[39m'\u001b[39m, filepath)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=990'>991</a>\u001b[0m img \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mones((math\u001b[39m.\u001b[39;49mceil(height), math\u001b[39m.\u001b[39;49mceil(width), \u001b[39m3\u001b[39;49m))\u001b[39m.\u001b[39;49mastype(np\u001b[39m.\u001b[39;49muint8) \u001b[39m*\u001b[39;49m \u001b[39m255\u001b[39;49m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=991'>992</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m bbox_edge:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=992'>993</a>\u001b[0m     cv2\u001b[39m.\u001b[39mline(img, \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=993'>994</a>\u001b[0m         (\u001b[39mint\u001b[39m(pos[e[\u001b[39m0\u001b[39m], \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m width), \u001b[39mint\u001b[39m(pos[e[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m height)), \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=994'>995</a>\u001b[0m         (\u001b[39mint\u001b[39m(pos[e[\u001b[39m1\u001b[39m], \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m width), \u001b[39mint\u001b[39m(pos[e[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m height)), \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=995'>996</a>\u001b[0m         (\u001b[39m255\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m), \n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=996'>997</a>\u001b[0m         \u001b[39m5\u001b[39m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/ottos/akariinc/YOLaT-VectorGraphicsRecognition/dataflow.ipynb#X13sZmlsZQ%3D%3D?line=997'>998</a>\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = CADDataset(opt.data_dir, opt, partition = 'train', data_aug = False, do_mixup = False, drop_edge = opt.drop_edge, bbox_sampling_step = 2)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CADDataset(opt.data_dir, opt, partition = 'train', data_aug = opt.data_aug, do_mixup = opt.do_mixup, drop_edge = opt.drop_edge, bbox_sampling_step = opt.bbox_sampling_step)\n",
    "train_loader = DataLoader(train_dataset, \n",
    "    batch_size=opt.batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn = collate)\n",
    "\n",
    "test_dataset = CADDataset(opt.data_dir, opt, partition = 'test', data_aug = False, do_mixup = False, drop_edge = False, bbox_sampling_step = opt.bbox_sampling_step)\n",
    "test_loader = DataLoader(test_dataset, \n",
    "    batch_size=opt.batch_size * 2, \n",
    "    shuffle=False, \n",
    "    collate_fn = collate)\n",
    "\n",
    "#    if opt.multi_gpus:\n",
    "#        train_loader = DataListLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=4)\n",
    "#    else:\n",
    "#        train_loader = DataLoader(train_dataset, batch_size=opt.batch_size, shuffle=True, num_workers=4)\n",
    "opt.n_classes = len(list(set(train_dataset.class_dict.values())))\n",
    "opt.in_channels = test_dataset[0].x.shape[1]\n",
    "opt.n_objects = train_dataset.n_objects\n",
    "\n",
    "logging.info('===> Loading the network ...')\n",
    "    \n",
    "model = SparseCADGCN(opt).to(opt.device)\n",
    "\n",
    "\n",
    "if opt.multi_gpus:\n",
    "    model = DataParallel(SparseDeepGCN(opt)).to(opt.device)\n",
    "logging.info('===> loading pre-trained ...')\n",
    "model, opt.best_value, opt.epoch = load_pretrained_models(model, opt.pretrained_model, opt.phase)\n",
    "logging.info(model)\n",
    "\n",
    "logging.info('===> Init the optimizer ...')\n",
    "criterion = DetectionLoss(opt) #torch.nn.CrossEntropyLoss().to(opt.device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, weight_decay = opt.weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, opt.lr_adjust_freq, opt.lr_decay_rate)\n",
    "optimizer, scheduler, opt.lr = load_pretrained_optimizer(opt.pretrained_model, optimizer, scheduler, opt.lr)\n",
    "\n",
    "logging.info('===> Init Metric ...')\n",
    "opt.losses = AverageMeter()\n",
    "# opt.test_metric = miou\n",
    "opt.test_values = AverageMeter()\n",
    "opt.test_value = 0.\n",
    "\n",
    "logging.info('===> start training ...')\n",
    "for _ in range(opt.total_epochs):\n",
    "    opt.epoch += 1\n",
    "    train(model, train_loader, optimizer, scheduler, criterion, opt)\n",
    "    if opt.epoch % 1 == 0 and opt.epoch >= 2:\n",
    "        test_value = test(model, test_loader, criterion, opt)\n",
    "    scheduler.step()\n",
    "logging.info('Saving the final model.Finish!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subcluster loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = []\n",
    "for cc_idx, cluster in enumerate(cc):\n",
    "    #cluster = [i for i in cluster if not is_super[i]]\n",
    "    pos_cluster = pos[cluster, :]\n",
    "    #print(pos_cluster)\n",
    "\n",
    "    max_x = pos_cluster[:, 0].max(0)\n",
    "    min_x = pos_cluster[:, 0].min(0)\n",
    "    max_y = pos_cluster[:, 1].max(0)\n",
    "    min_y = pos_cluster[:, 1].min(0)\n",
    "\n",
    "    #########################\n",
    "    x_values = sorted(pos_cluster[:, 0])\n",
    "    y_values = sorted(pos_cluster[:, 1])\n",
    "    #print('fooo', x_values, y_values)\n",
    "    def merge_values(values):\n",
    "        new_values  = [values[0]]\n",
    "        for i in range(1, len(values)):\n",
    "            if values[i] != values[i - 1]: #> 1e-3:\n",
    "                new_values.append(values[i])\n",
    "        return new_values\n",
    "    x_values = merge_values(x_values)\n",
    "    y_values = merge_values(y_values)\n",
    "    #print(x_values, y_values)\n",
    "\n",
    "    def get_values_dict(values):\n",
    "        values_dict = {}\n",
    "        for i, v in enumerate(values):\n",
    "            values_dict[v] = i\n",
    "        return values_dict\n",
    "    x_values_dict = get_values_dict(x_values)\n",
    "    y_values_dict = get_values_dict(y_values)\n",
    "\n",
    "    use_bit = False\n",
    "\n",
    "    #point_exist = np.ones((len(y_values), len(x_values))).astype(np.int8) * (-1)\n",
    "    point_exist = [[[] for j in range(len(x_values))] for i in range(len(y_values))]\n",
    "    #print(x_values, y_values)\n",
    "\n",
    "    pos_idx = range(pos_cluster.shape[0])\n",
    "    if use_bit and len(pos_idx) > 64:\n",
    "        print('more than 64 points in cc', len(pos_idx))\n",
    "        pos_idx = random.sample(pos_idx, 64)\n",
    "\n",
    "    for i in pos_idx:\n",
    "        p = pos_cluster[i]                \n",
    "        point_exist[y_values_dict[p[1]]][x_values_dict[p[0]]].append(i)\n",
    "\n",
    "    \n",
    "    def set_bit(value, bit):\n",
    "        return value | (1<<bit)\n",
    "\n",
    "    d00 = [[None for i in range(len(x_values))] for j in range(len(y_values))]\n",
    "    d00[0][0] = point_exist[0][0]\n",
    "\n",
    "    for i in range(1, len(x_values)):\n",
    "        d00[0][i] = d00[0][i - 1] + point_exist[0][i]\n",
    "\n",
    "    for i in range(1, len(y_values)):\n",
    "        d00[i][0] = d00[i - 1][0] + point_exist[i][0]\n",
    "\n",
    "    d_row = [[None for i in range(len(x_values))] for j in range(len(y_values))]\n",
    "    for i in range(0, len(x_values)):\n",
    "        d_row[0][i] = d00[0][i]\n",
    "\n",
    "    for i in range(1, len(y_values)):\n",
    "        d_row[i][0] = point_exist[i][0]\n",
    "\n",
    "    for y in range(1, len(y_values)):\n",
    "        for x in range(1, len(x_values)):\n",
    "            d_row[y][x] = d_row[y][x - 1] + point_exist[y][x]\n",
    "            d00[y][x] = d00[y - 1][x] + d_row[y][x]\n",
    "\n",
    "    for y in range(0, len(y_values)):\n",
    "        for x in range(0, len(x_values)):\n",
    "            d00[y][x] = set(d00[y][x])\n",
    "\n",
    "    sub_clusters = []\n",
    "    #print(len(y_values),len(x_values))\n",
    "\n",
    "\n",
    "    x_step = (max_x - min_x) / bbox_sampling_step #10 #5 #5#25\n",
    "    y_step = (max_y - min_y) / bbox_sampling_step #10 #5 #5\n",
    "    #print('x_step', x_step, 'y_step', y_step)\n",
    "    #print(d00)\n",
    "\n",
    "    x_grids = np.arange(min_x, max_x, x_step)\n",
    "    y_grids = np.arange(min_y, max_y, y_step)\n",
    "\n",
    "\n",
    "    x_grids = np.append(x_grids, max_x)\n",
    "    y_grids = np.append(y_grids, max_y)\n",
    "\n",
    "    #print(x_grids, y_grids)\n",
    "    def move_endpoint(x, values, bound):\n",
    "        if x >= len(values):\n",
    "            return x - 1\n",
    "\n",
    "        while values[x] <= bound:\n",
    "            x += 1\n",
    "            if x >= len(values):\n",
    "                break\n",
    "        return x - 1\n",
    "\n",
    "    def move_endpoint_close(x, values, bound):\n",
    "        if x >= len(values):\n",
    "            return x - 1\n",
    "\n",
    "        while values[x] < bound:\n",
    "            x += 1\n",
    "            if x >= len(values):\n",
    "                break\n",
    "        return x - 1\n",
    "\n",
    "    prev_y0 = -1\n",
    "    grid_y0 = 0\n",
    "    for i_grid_y0, grid_y0 in enumerate(y_grids):\n",
    "        y0 = move_endpoint_close(prev_y0 + 1, y_values, grid_y0)\n",
    "        if y0 != len(y_values): y0 += 1\n",
    "        if y0 == prev_y0: continue\n",
    "        prev_y0 = y0\n",
    "        \n",
    "        grid_x0 = x_values[0]\n",
    "        prev_x0 = -1\n",
    "        for i_grid_x0, grid_x0 in enumerate(x_grids):\n",
    "            x0 = move_endpoint_close(prev_x0 + 1, x_values, grid_x0)\n",
    "            if x0 != len(y_values): x0 += 1\n",
    "            if x0 == prev_x0: continue\n",
    "            prev_x0 = x0\n",
    "            \n",
    "            #grid_y1 = grid_y0\n",
    "            prev_y1 = y0\n",
    "            for grid_y1 in y_grids[i_grid_y0 + 1 :]:\n",
    "                y1 = move_endpoint(prev_y1 + 1, y_values, grid_y1)\n",
    "                #if prev_y1 + 1 < len(y_values):\n",
    "                #    print(prev_y1 + 1, y_values[prev_y1 + 1], 'to', grid_y1)\n",
    "                if y1 == prev_y1: continue\n",
    "                #print('---------------', prev_y1, 'to', y1, y_values[prev_y1], 'to', grid_y1)\n",
    "                prev_y1 = y1\n",
    "                \n",
    "                #grid_x1 = grid_x0\n",
    "                prev_x1 = x0\n",
    "                for grid_x1 in x_grids[i_grid_x0 + 1:]:\n",
    "                    x1 = move_endpoint(prev_x1 + 1, x_values, grid_x1)\n",
    "                    if x1 == prev_x1: continue\n",
    "                    prev_x1 = x1\n",
    "                    \n",
    "                    if use_bit:\n",
    "                        if x0 > 0 and y0 > 0:\n",
    "                            dd = d00[y1][x1] - (d00[y1][x0 - 1] | d00[y0 - 1][x1])\n",
    "                        elif x0 > 0 and y0 == 0:\n",
    "                            dd = d00[y1][x1] - d00[y1][x0 - 1]\n",
    "                        elif y0 > 0 and x0 == 0:\n",
    "                            dd = d00[y1][x1] - d00[y0 - 1][x1]\n",
    "                        else:\n",
    "                            dd = d00[y1][x1]\n",
    "                        if dd == 0: continue\n",
    "                        count = 0\n",
    "                        sub_c = []\n",
    "                        while dd != 0:\n",
    "                            if dd & 1:\n",
    "                                sub_c.append(count)\n",
    "                            count += 1\n",
    "                            dd = dd >> 1\n",
    "                        sub_c = [cluster[ii] for ii in sub_c]\n",
    "                        sub_clusters.append(tuple(sub_c))\n",
    "                    else:\n",
    "                        if x0 > 0 and y0 > 0:\n",
    "                            dd = d00[y1][x1].difference(d00[y1][x0 - 1]).difference(d00[y0 - 1][x1])\n",
    "                        elif x0 > 0 and y0 == 0:\n",
    "                            dd = d00[y1][x1].difference(d00[y1][x0 - 1])\n",
    "                        elif y0 > 0 and x0 == 0:\n",
    "                            dd = d00[y1][x1].difference(d00[y0 - 1][x1])\n",
    "                        else:\n",
    "                            dd = d00[y1][x1]\n",
    "                        #print(x0, y0, x1, y1, 'fooo')\n",
    "                        sub_c = [cluster[ii] for ii in dd]\n",
    "                        sub_clusters.append(tuple(sorted(sub_c)))\n",
    "\n",
    "    sub_clusters = list(set(sub_clusters))\n",
    "    sc.extend(sub_clusters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26b2efd807f332db2ccea33febb7b99eac3c8f4f41a9efdfd4d1aeee358f104e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
